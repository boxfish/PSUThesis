%!TEX root = ../BoYu-Dissertation.tex
\graphicspath{{Figures/}}

\chapter{Our Approach: Knowledge Updating} % (fold)
\label{cha:knowledge_updating}
1. initial construction of PlanGraph, local scopes based on roles, 
2. intention update
3. belief update using Bayesian

both update the knowledge and enrich the events


how to update depends on what needs to be updated?
1. how to update capabilities? actor's beliefs, reasoning by system
2. how to update intentions? actor's beliefs, reasoning by system
3. how to update states? Bayesian network
4. what else?

system's comprehension: update the knowledge
system's projection: enrich the events


conseqence of external events:
Direct change to entities and relations
triggering events
the effect of actions

internal events:
Intentions
beliefs about capability, state, 
contribute to plan or replan


\section{Construction and Development of the Model} % (fold)
\label{sec:construction_and_development_of_the_model}
Therefore, the development of a collaborative activity can be represented as a dynamic process of constructing a PlanGraph. Before the collaboration begins, the PlanGraph is empty. As agents perform some actions to fulfill the shared goal, new plan nodes are introduced to the PlanGraph. If the root action in the PlanGraph is complex, agents will decompose it by selecting a recipe collaboratively. Then, agents move their attention to the parameters and sub-actions. These sub-actions may themselves be complex, and will become the subjects of further elaboration to form a sub-plan for performing. In the course of development, the PlanGraph will store the mental states of the agents toward each action node and update them in corresponding slots. 



different ways to do it:

1. the development of algorithms and heuristics for inferring mental state on the basis of observed actions While these algorithms and heuristics are domain independent, they require much rich domain-specific knowledge to work.

2. Human complementary work has attempted to avoid the problem of intent recognition by developing domain- specific languages and interfaces that allow users to specify their goals and plans directly.


these capabilities can be added incrementally to the basic approach to ensure a favorable ratio of cost (of knowledge engineering and runtime computation) to benefit (enhanced user performance). In addition, both more and less complicated versions of these capabilities exist and can be applied. For example, goal recognition can be done the hard way, i.e. using AI plan recognition techniques. However, a very simple technique is to hard-wire in one or more domain goals. As discussed above, a third approach (of intermediate complexity) is to represent domain goals and plans in the interface and allow users to specify them explicitly. Fischer and colleagues 85.s6 discuss how combining a goal specifica- tion component with a critiquing system improves the quality of system advice t


Information about users may be acquired explicitly, by engaging a user in an interaction expressly designed to acquire information, or implicitly, inferring information on the basis of user actions 58. Both methods have draw- backs. If users must answer system questions or fill out a form, they may find this obtrusive and may have a difficult time characterizing themselves accurately. On the other hand, implicit acquisition can be a difficult computational task, depending on the type of user model being constructed. Plan recognition, as previ- ously mentioned, is a very difficult computational problem. Among other things, it is difficult to know when a user is starting a new plan (as opposed to continuing the current one), users may suspend and resume plans, actions may be part of more than one plan, and there may be multiple plans for a single goaP 6. Stereotypes can be easier to recognize; each stereotype generally has a triggering condition that, when satisfied, leads the system to categorize the user as a member of that stereotype. Also, some representations of user pref- erences are fairly simple, and thus can be computed easily. For example, simple statistics on what messages a user reads in Net News may allow a system to filter the messages the user sees in the future 7Â°.


However, ITS researchers have been active in designing interaction techniques that allow users to express their intent directly, rather than requiring the system to guess it 72-74.. By analyzing how a class of users works within a particular task domain, say symbolic integration, financial analysis, or medical diagnosis, researchers develop a set of goals and plans for achieving these goals. These goals and plans are represented formally in a knowledge representation language and also represented graphically as objects in a direct manipulation interface 43. Users then directly specify their goals and plans. This benefits both user and system. The user is given a medium for making problem solving explicit, rather than having to do it mentally or using noncomputational aids such as paper and pencil. The system gains access to a high-level specification of what it is that the user is trying to accomplish, thus simplifying the computations required to play a useful role in the interaction. For example, computations to track and display finished and unfinished steps in the plan, to fill in low-level details required in executing a plan, and to determine whether a plan is inappropriate are very useful and much simpler than plan recognition. Checklists 75,76, computerized versions of the everyday to- do list, are a specific interaction resource used for orga- nizing interaction and tracking and displaying progress toward a goal.

Systems by Self for logic tutoring 73 and Singley for
algebra rate of change problems 77 explored the use of `goal posting'. For example, in Singley's system, a user selects a goal such as `find dp/dt in terms of t'. She next chooses a plan operator for achieving the goal, such as using the chain rule. Several subgoals might have to be satisfied before the operator can be applied. At all times, the system keeps track of which goals have and have not been satisfied, visually differentiating the current goal, satisfied goals, and unsatisfied goals. Empirical studies showed that the goal posting tech- nique improved user performance and facilitated learn- ing.

In addition to techniques for directly specifying goals,
another important notion is the incremental specifica- tion of goals. People typically do not form precise defi- nitions of goals to accomplish, then plan to achieve their goals, and then carry out their plans. Rather, acting, planning, and forming and pursuing goals are interleaved. A number of interaction techniques have been explored that support incremental specification of goals in exploratory activity. The retrieval by reformula- tion 8~82 information retrieval technique interleaves query definition, querying, and evaluation of results. Experiments with critics (discussed in detail in the next section) have shown that users may refine their goals on the basis of the delivery of advice from a system about user actions. They begin by specifying information they know and care about, and then gradually refine and elaborate it in response to system advice


\subsection{The Development of PlanGraph} % (fold)
\label{sub:the_development_of_plangraph}





Considering the collaborative activity as a process from a partial SharedPlan to a full SharedPlan among the participants, the PlanGraph, which is used to represent the collaborative activity, should also be considered as dynamically developed. To facilitate the development of PlanGraph, the PlanGraph model provides the reasoning mechanisms to decide how the interaction between the system and human participants, or between the human participants, influences the state of collaborative activity and update the changes in the PlanGraph. In general, the reasoning mechanism in PlanGraph model includes two steps: the plan explanation and the plan elaboration.

\subsubsection*{Plan Explanation}
Participants in a collaborative activity need to interact with each other to contribute to the activity. It is through the communication between the participants that collaboration can be enacted. Therefore, the input of an agent can be treated as the way that the agent tries to express their intentions to the other agents in the collaborative activity. Plan explanation is the step where the system attempts to explain how the meanings of the new piece of interaction relate to the current PlanGraph. In general, the new input is said to be meaningfully merged with the current collaboration context if one of the following conditions is satisfied:

\begin{enumerate}
\item The new input provides a piece of information that helps the agents to assign/change a value to a parameter in the current PlanGraph. 
\item The new input provides more details on the performance of a complex action in the PlanGraph. For example, the user suggests performing a sub-action or identifying a parameter in order to complete the action.
\item The new input helps to establishing necessary mental states for a collaborative action. In this case, the agent's new input serves as an indicator of the speaker's mental attitudes, such as confirmation or refusal towards certain states of fairs. 
\end{enumerate}

If the new user input can be successfully explained in current PlanGraph, it will be merged to update the PlanGraph accordingly, i.e. the contextual information about the ongoing activity is changed.

\subsubsection*{Plan Elaboration}
The main goal in elaboration stage is to advance the collaborative activity from the system side based on the change from the new input. After the interpretation process, the context of the activity is changed. Therefore, the system needs to elaborate the PlanGraph to accommodate the changes. The elaboration process begins with the root node of the PlanGraph and uses the depth-first traverse to visit the whole plan based on reasoning rules associated with PlanGraph model. The elaboration ends when no more parts of the PlanGraph can be further elaborated.

The system can elaborate the PlanGraph in several ways. First, the system can contribute to the collaborative activity by retrieving a recipe for an action from the knowledge base. Second, the system can execute the basic actions that can be performed without further inputs from other human agents. Lastly, the system can identify the value for a parameter by retrieving the default or suggested values from the knowledge base. 

After the elaboration process, the PlanGraph again reflects the current state of the collaborative activity. Therefore, the information from the PlanGraph can be used by the system to represent the current state of the activity context. 

This elaboration process also attempts to discover all the open nodes in the PlanGraph that might be addressed later in the collaboration, such as unidentified parameters, unperformed actions, conflicting beliefs, missing details, or ambiguous choices. These possible open nodes are   stored in an agenda to include all the possible attentional states that require further development in the collaboration. During the elaboration process, when the system encounters some problem to elaborate an action node, is unable to identify the value of a parameter, or fail to execute an action, the system will put the node into the agenda.
% subsection the_development_of_plangraph (end) 

% section construction_and_development_of_the_model (end)

% chapter knowledge_updating (end)




 

